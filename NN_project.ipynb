{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Giving access to the drive"
      ],
      "metadata": {
        "id": "na3Nq-Cf_pJR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux3mxJBCKL-n",
        "outputId": "95c380ae-5372-4e2e-9a6a-02aa9f2cae6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing detectron2"
      ],
      "metadata": {
        "id": "UquDHPqu_drh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0SJ8trh3Fb8"
      },
      "outputs": [],
      "source": [
        "!pip install pyyaml==5.1\n",
        "\n",
        "import torch\n",
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "# Install detectron2 that matches the above pytorch version\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/$CUDA_VERSION/torch$TORCH_VERSION/index.html\n",
        "# If there is not yet a detectron2 release that matches the given torch + CUDA version, you need to install a different pytorch.\n",
        "\n",
        "# exit(0)  # After installation, you may need to \"restart runtime\" in Colab. This line can also restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qnh_dSWN3Qnk"
      },
      "outputs": [],
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "#Drive access\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-rEitSePL9c"
      },
      "source": [
        "**Registering the datasets** : Here Resgestering the dataset beause that datset is custom format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cycH8sg93Yec"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import json\n",
        "from detectron2.structures import BoxMode\n",
        "\n",
        "def get_amazonrobo_dicts(directory):\n",
        "    classes = ['blueball', 'greenball', 'orangeblock', 'cube', 'greenbox', 'woodenblock', 'whitebox', 'blackbag', 'ereaser', 'battery'] #10 classes\n",
        "    dataset_dicts = []\n",
        "    for filename in [file for file in os.listdir(directory) if file.endswith('.json')]:\n",
        "        json_file = os.path.join(directory, filename)\n",
        "        with open(json_file) as f:\n",
        "            img_anns = json.load(f)\n",
        "\n",
        "        record = {}\n",
        "        \n",
        "        filename = os.path.join(directory, img_anns[\"imagePath\"])\n",
        "        \n",
        "        record[\"file_name\"] = filename\n",
        "        record[\"height\"] = 720\n",
        "        record[\"width\"] = 1280\n",
        "      \n",
        "        annos = img_anns[\"shapes\"]\n",
        "        objs = []\n",
        "        for anno in annos:\n",
        "            px = [a[0] for a in anno['points']]\n",
        "            py = [a[1] for a in anno['points']]\n",
        "            poly = [(x, y) for x, y in zip(px, py)]\n",
        "            poly = [p for x in poly for p in x]\n",
        "\n",
        "            obj = {\n",
        "                \"bbox\": [np.min(px), np.min(py), np.max(px), np.max(py)],\n",
        "                \"bbox_mode\": BoxMode.XYXY_ABS,\n",
        "                \"segmentation\": [poly],\n",
        "                \"category_id\": classes.index(anno['label']),\n",
        "                \"iscrowd\": 0\n",
        "            }\n",
        "            objs.append(obj)\n",
        "        record[\"annotations\"] = objs\n",
        "        dataset_dicts.append(record)\n",
        "    return dataset_dicts\n",
        "#inside train and val: .png and .json\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "for d in [\"train\", \"valid\"]:\n",
        "    DatasetCatalog.register(\"my_dataset_\" + d, lambda d=d: get_amazonrobo_dicts('/content/gdrive/MyDrive/NN_class10/'+ d)) #path to train and val directory in the drive\n",
        "    MetadataCatalog.get(\"my_dataset_\" + d).set(thing_classes=['blueball', 'greenball', 'orangeblock', 'cube', 'greenbox', 'woodenblock', 'whitebox', 'blackbag', 'ereaser', 'battery'])\n",
        "amazonrobo_metadata = MetadataCatalog.get(\"my_dataset_train\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RotyFgXKUqi"
      },
      "source": [
        "**Verifying the data loading:** Randomly picking 4 samples to visualize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkqIlAFYHTmF"
      },
      "outputs": [],
      "source": [
        "dataset_dicts = get_amazonrobo_dicts(\"/content/gdrive/MyDrive/NN_class10/train\")\n",
        "for d in random.sample(dataset_dicts, 2):  #checking 2 random sample\n",
        "    img = cv2.imread(d[\"file_name\"])\n",
        "    visualizer = Visualizer(img[:, :, ::-1], metadata=amazonrobo_metadata, scale=0.5)\n",
        "    out = visualizer.draw_dataset_dict(d)\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAULDk6YO-Zp"
      },
      "source": [
        "**Training the model** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXfSpNOP3xUW"
      },
      "outputs": [],
      "source": [
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.config import get_cfg\n",
        "\n",
        "cfg = get_cfg()\n",
        "#Use either RetinaNet or Mask R-CNN\n",
        "#model_file = \"COCO-Detection/retinanet_R_50_FPN_3x.yaml\" # RetinaNet for bounding box detection\n",
        "model_file = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\" # Mask R-CNN for instance segmentation\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(model_file))\n",
        "cfg.DATASETS.TRAIN = (\"my_dataset_train\",)\n",
        "cfg.DATASETS.TEST = ()\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_file)\n",
        "cfg.SOLVER.IMS_PER_BATCH = 2     # Lower to reduce memory usage (1 is the lowest)\n",
        "cfg.SOLVER.BASE_LR = 0.00025      # Base learning rate\n",
        "cfg.SOLVER.MAX_ITER = 1800        # Maximum number of iterations\n",
        "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10    #number of classes  \n",
        "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
        "# Create a default training pipeline and begin training\n",
        "trainer = DefaultTrainer(cfg) \n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n",
        "#cfg.TEST.EVAL_PERIOD = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mn71TboTLTuW"
      },
      "source": [
        "**Training curve in tensorboard**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZr_SrgzLPd9"
      },
      "outputs": [],
      "source": [
        "# Looking at training curves in tensorboard:\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi0gnVwaPZmI"
      },
      "source": [
        "**Validating :** Now runnning the trained model on validating dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nII4zQlj6jqb"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\") # path to the model we just trained\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7        # set a custom testing threshold\n",
        "cfg.DATASETS.TEST = (\"my_dataset_valid\", )\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzRE_6Bn6qkF"
      },
      "outputs": [],
      "source": [
        "from detectron2.utils.visualizer import ColorMode\n",
        "dataset_dicts = get_amazonrobo_dicts('/content/gdrive/MyDrive/NN_class10/val')\n",
        "#Validating 4 images from validating dataset\n",
        "for i in range(4):    \n",
        "    im = cv2.imread(d[\"file_name\"])\n",
        "    outputs = predictor(im)\n",
        "    v = Visualizer(im[:, :, ::-1],\n",
        "                   metadata=amazonrobo_metadata, \n",
        "                   scale=0.5, \n",
        "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
        "    )\n",
        "    out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    cv2_imshow(out.get_image()[:, :, ::-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running Detectron2 on test dataset"
      ],
      "metadata": {
        "id": "0Y3u2nuLv6LG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "AnpyFzjA1mM-"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "filename = '/content/gdrive/MyDrive/NN_class10/config.pkl'\n",
        "with open(filename, 'wb') as f:\n",
        "     pickle.dump(cfg, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Generalizing with a single image."
      ],
      "metadata": {
        "id": "YWNjrFFAwHTN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1dLkKC416m5"
      },
      "outputs": [],
      "source": [
        "filename = '/content/gdrive/MyDrive/NN_class10/config.pkl'\n",
        "with open(filename, 'rb') as f:\n",
        "     cfg = pickle.load(f)\n",
        "predictor = DefaultPredictor(cfg)\n",
        "def GetMask(img):\n",
        "    outputs = predictor(img)\n",
        "    v = Visualizer(im[:, :, ::-1], \n",
        "                   MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), \n",
        "                   scale=0.7, \n",
        "                   instance_mode=ColorMode.IMAGE_BW)\n",
        "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "    \n",
        "    return v.get_image()[:, :, ::-1]\n",
        "\n",
        "im = cv2.imread(\"/content/gdrive/MyDrive/NN_class10/test/download (39).png\")\n",
        "cv2_imshow(GetMask(im))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "amazon_project_class10",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}